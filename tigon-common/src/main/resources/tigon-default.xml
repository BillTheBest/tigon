<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Copyright Â© 2014 Cask Data, Inc.

  Licensed under the Apache License, Version 2.0 (the "License"); you may not
  use this file except in compliance with the License. You may obtain a copy of
  the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
  License for the specific language governing permissions and limitations under
  the License.
  -->
<configuration>

    <property>
        <name>root.namespace</name>
        <value>cdap</value>
        <description>Specifies the root namespace</description>
    </property>

    <property>
        <name>zookeeper.quorum</name>
        <value>127.0.0.1/${root.namespace}</value>
        <description>Specifies the zookeeper quorum string</description>
    </property>

    <property>
        <name>zookeeper.session.timeout.millis</name>
        <value>40000</value>
        <description>Specifies the zookeeper session time out; time unit milliseconds</description>
    </property>

    <property>
        <name>thrift.max.read.buffer</name>
        <value>16777216</value>
        <description>
            Specifies the max read buffer size used by
            thrift server. Value should be set to something greater
            than max frame that is sent on RPC channel.
        </description>
    </property>

    <property>
        <name>twill.zookeeper.namespace</name>
        <value>/twill</value>
        <description>Zookeeper namespace prefix for Apache Twill</description>
    </property>

    <property>
        <name>twill.java.reserved.memory.mb</name>
        <value>250</value>
        <description>
            Reserved non-heap memory in MB for Apache Twill container.
        </description>
    </property>

    <property>
        <name>twill.no.container.timeout</name>
        <value>120000</value>
        <description>
            Amount of time in milliseconds to wait for at least one container for Apache Twill runnable
        </description>
    </property>

    <property>
        <name>twill.jvm.gc.opts</name>
        <value>-verbose:gc -Xloggc:&lt;LOG_DIR&gt;/gc.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M</value>
        <description>Java GC options for all Apache Twill containers</description>
    </property>

    <property>
        <name>hdfs.namespace</name>
        <value>/${root.namespace}</value>
        <description>Namespace for HDFS files</description>
    </property>

    <property>
        <name>hdfs.user</name>
        <value>yarn</value>
        <description>User name for accessing HDFS</description>
    </property>

    <property>
        <name>yarn.user</name>
        <value>yarn</value>
        <description>User name for running applications in YARN</description>
    </property>

    <property>
        <name>local.data.dir</name>
        <value>data</value>
        <description>Data directory for local mode</description>
    </property>

    <property>
        <name>hdfs.lib.dir</name>
        <value>${hdfs.namespace}/lib</value>
        <description>Common directory in HDFS for jar files for coprocessors,
        etc.</description>
    </property>

    <!-- Monitor Handler Parameters -->

    <property>
      <name>monitor.handler.service.discovery.timeout.seconds</name>
      <value>1</value>
      <description>Timeout in seconds for service discovery used in Monitor Handler Service Status check</description>
    </property>

    <!-- YARN Services Parameters -->

    <property>
        <name>master.service.num.cores</name>
        <value>2</value>
        <description>Number of cores for Master Service instance</description>
    </property>

    <property>
        <name>master.service.memory.mb</name>
        <value>512</value>
        <description>Size of Memory in MB for Master Service instance</description>
    </property>

    <property>
        <name>master.service.max.instances</name>
        <value>5</value>
        <description>Maximum Number of Master Service Instances</description>
    </property>

    <!--
        Data Fabric Configuration
    -->
    <property>
        <name>data.local.storage</name>
        <value>${local.data.dir}/ldb</value>
        <description>Specifies the database directory</description>
    </property>

    <property>
        <name>data.local.storage.blocksize</name>
        <value>1024</value>
        <description>Specifies block size (in bytes)</description>
    </property>

    <property>
        <name>data.local.storage.cachesize</name>
        <value>104857600</value>
        <description>Specifies cache size (in bytes)</description>
    </property>

    <property>
        <name>data.tx.bind.port</name>
        <value>15165</value>
        <description>The port number for the transaction
            service</description>
    </property>

    <property>
        <name>data.tx.bind.address</name>
        <value>127.0.0.1</value>
        <description>The inet address for the transaction
            service</description>
    </property>

    <property>
        <name>data.tx.server.io.threads</name>
        <value>2</value>
        <description>The number of IO threads for the transaction
            service</description>
    </property>

    <property>
        <name>data.tx.server.threads</name>
        <value>25</value>
        <description>The number of threads for the transaction
            service</description>
    </property>

    <property>
        <name>data.tx.discovery.service.name</name>
        <value>transaction</value>
        <description>Name in discovery service for the transaction service</description>
    </property>

    <property>
        <name>data.tx.client.count</name>
        <value>5</value>
        <description>The number of pooled instanced of the transaction
            client</description>
    </property>

    <property>
        <name>data.tx.client.provider</name>
        <value>thread-local</value>
        <description>The provider strategy for transaction clients;
            valid values are "pool" and "thread-local"</description>
    </property>

    <property>
        <name>data.tx.thrift.max.read.buffer</name>
        <value>${thrift.max.read.buffer}</value>
        <description>
          Specifies the max read buffer size used by
          transaction server. Value should be set to something greater
          than max frame that is sent on RPC channel.
        </description>
    </property>

    <property>
        <name>data.tx.hdfs.user</name>
        <value>${hdfs.user}</value>
        <description>User name for accessing HDFS if not running in secure HDFS</description>
    </property>

    <property>
        <name>data.queue.table.name</name>
        <value>queues</value>
        <description>Specifies the name of the table for queues</description>
    </property>

    <property>
        <name>data.tx.snapshot.codecs</name>
        <value>
          co.cask.tigon.data.transaction.snapshot.SnapshotCodecV1,
          co.cask.tigon.data.transaction.snapshot.SnapshotCodecV2
        </value>
        <description>Specifies the class names of all supported transaction state codecs</description>
    </property>

    <property>
        <name>data.tx.snapshot.dir</name>
        <value>${hdfs.namespace}/tx.snapshot</value>
        <description>Directory in HDFS used to store snapshots and logs of
            transaction state</description>
    </property>

    <property>
        <name>data.tx.snapshot.local.dir</name>
        <value>${local.data.dir}/tx.snapshot</value>
        <description>Directory on the local filesystem used to store snapshots
        and logs of transaction state for single-node operation</description>
    </property>

    <property>
        <name>data.tx.snapshot.interval</name>
        <value>300</value>
        <description>Frequency, in seconds, at which snapshots of transaction
            state should be written</description>
    </property>

    <property>
        <name>data.tx.snapshot.retain</name>
        <value>10</value>
        <description>Number of transaction snapshot files to retain as
            backups</description>
    </property>

    <property>
        <name>data.tx.janitor.enable</name>
        <value>true</value>
        <description>Whether or not the TransactionDataJanitor coprocessor
        should be enabled on tables; should normally be true</description>
    </property>

    <property>
        <name>data.tx.num.instances</name>
        <value>1</value>
    </property>

    <property>
        <name>data.tx.max.instances</name>
        <value>${master.service.max.instances}</value>
    </property>

    <property>
        <name>data.tx.num.cores</name>
        <value>${master.service.num.cores}</value>
    </property>

    <property>
        <name>data.tx.memory.mb</name>
        <value>${master.service.memory.mb}</value>
    </property>

    <!--
        Queue-related Configuration
    -->
    <property>
        <name>data.queue.config.update.interval</name>
        <value>5</value>
        <description>Frequency, in seconds, of updates to the queue consumer
        configuration used in evicting queue entries on flush and compaction
        </description>
    </property>

    <!--
        Metadata Service Configuration
    -->
    <property>
        <name>metadata.bind.address</name>
        <value>127.0.0.1</value>
        <description>Specifies the server address of metadata
            server</description>
    </property>

    <property>
        <name>metadata.bind.port</name>
        <value>45004</value>
        <description>Specifies the port on which metdata server
            is started on</description>
    </property>


    <property>
        <name>metadata.program.run.history.keepdays</name>
        <value>30</value>
        <description>Specifies the number of days to keep
            program run run-history in metadata</description>
    </property>

    <!--
        Log collection service configuration
    -->
    <property>
        <name>log.query.bind.address</name>
        <value>127.0.0.1</value>
        <description>Specifies the server address of metrics frontend
            server</description>
    </property>

    <property>
        <name>log.query.bind.port</name>
        <value>45002</value>
        <description>Specifies the port on which frontend metrics server
            is started on</description>
    </property>

    <property>
        <name>log.collection.bind.address</name>
        <value>127.0.0.1</value>
        <description>Specifies the hostname where the collection service runs</description>
    </property>

    <property>
        <name>log.collection.bind.port</name>
        <value>12157</value>
        <description>Port the log collection service runs on</description>
    </property>

    <property>
        <name>log.collection.root</name>
        <value>${local.data.dir}/logs</value>
        <description>Root location for collecting logs</description>
    </property>


    <!-- App Fabric related changes -->
    <property>
        <name>app.bind.address</name>
        <value>127.0.0.1</value>
        <description>Host address on which the app fabric server is started</description>
    </property>

    <property>
        <name>app.output.dir</name>
        <value>/programs</value>
        <description>Directory where all archives are stored</description>
    </property>

    <property>
        <name>dataset.table.prefix</name>
        <value>${root.namespace}</value>
        <description>Prefix for dataset table name</description>
    </property>

    <property>
        <name>dataset.service.output.dir</name>
        <value>/datasets</value>
        <description>Directory where all dataset modules archives are stored</description>
    </property>

    <property>
        <name>dataset.service.bind.address</name>
        <value>127.0.0.1</value>
        <description>DataSet service hostname</description>
    </property>

    <property>
        <name>dataset.executor.max.instances</name>
        <value>${master.service.max.instances}</value>
        <description>Maximum Number of DataSet Executor Instances</description>
    </property>

    <property>
        <name>dataset.executor.container.instances</name>
        <value>1</value>
        <description>Number of DataSet Executor Instances</description>
    </property>

    <property>
        <name>app.temp.dir</name>
        <value>/tmp</value>
        <description>Directory temp</description>
    </property>

    <property>
        <name>app.program.jvm.opts</name>
        <value>${twill.jvm.gc.opts}</value>
        <description>Java options for all program containers</description>
    </property>

    <!--
        Logging Configuration
    -->
    <property>
        <name>kafka.seed.brokers</name>
        <value>127.0.0.1:9092</value>
        <description>List of Kafka brokers (comma separated)</description>
    </property>

    <property>
        <name>log.publish.num.partitions</name>
        <value>10</value>
        <description>Number of Kafka partitions to publish the logs to</description>
    </property>

    <property>
        <name>log.base.dir</name>
        <value>/logs/avro</value>
        <description>Base log directory</description>
    </property>

    <property>
        <name>log.retention.duration.days</name>
        <value>7</value>
        <description>Log file hdfs retention duration in days</description>
    </property>

    <property>
        <name>log.cleanup.run.interval.mins</name>
        <value>1440</value>
        <description>Interval at which to run log cleanup</description>
    </property>

    <property>
        <name>log.saver.num.instances</name>
        <value>1</value>
        <description>Number of log saver instances to run in yarn</description>
    </property>

    <property>
        <name>log.saver.max.instances</name>
        <value>${master.service.max.instances}</value>
    </property>

    <property>
        <name>log.saver.run.memory.megs</name>
        <value>1024</value>
        <description>Memory in MB for log saver instances to run in yarn</description>
    </property>

    <property>
        <name>log.saver.status.bind.address</name>
        <value>127.0.0.1</value>
        <description>Default inet address for binding logsaver http service</description>
    </property>

    <!--
        Kafka Configuration
    -->
    <property>
        <name>kafka.bind.address</name>
        <value>0.0.0.0</value>
        <description>Kafka server hostname to bind to</description>
    </property>

    <property>
        <name>kafka.bind.port</name>
        <value>9092</value>
        <description>Kafka server port</description>
    </property>

    <property>
        <name>kafka.num.partitions</name>
        <value>10</value>
        <description>Default number of partitions for a topic</description>
    </property>

    <property>
        <name>kafka.log.dir</name>
        <value>/tmp/kafka-logs</value>
        <description>Directory to store Kafka logs</description>
    </property>

    <property>
        <name>kafka.zookeeper.namespace</name>
        <value>kafka</value>
        <description>ZK namespace for Kafka</description>
    </property>

    <property>
        <name>kafka.default.replication.factor</name>
        <value>1</value>
        <description>Kafka replication factor</description>
    </property>


</configuration>
